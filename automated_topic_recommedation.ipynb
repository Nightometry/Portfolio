{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "automated-topic-recommedation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R90q9co84Otw"
      },
      "source": [
        "#  Classification and Clustering Analysis: Automated Topic Recommendations\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Initiation and Data Preprocessing\n",
        "* Import Packages and Files\n",
        "* Data Cleaning\n",
        "\n",
        "Data Exploration and Analysis\n",
        "* Analyzing the Sources of the Text \n",
        "* Analyzing The Context of The Text \n",
        "\n",
        "Unsupervised Feature Preparation\n",
        "* Text Vectorization \n",
        "* Feature Reduction\n",
        "\n",
        "Creating Recommendations Using Cosine Similarity\n",
        "\n",
        "* Real-time Predictions\n",
        "* Batch Predictions\n",
        "\n",
        "Recommendation Analysis\n",
        "* Evaluating Recommendation Techniques\n",
        "\n",
        "Final Modeling Pipeline\n",
        "* Full Code\n",
        "* Analysis and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPLhls-LsPww"
      },
      "source": [
        "## Initiation and Data Preprocessing\n",
        "\n",
        "The data used in this study is taken from texts found in the Gutenberg corpora. \n",
        "Excerpts taken from the writing of the ten authors were used in clustering and classification.\n",
        "Excerpts were labeled using the authors' last names: Chesterton, Bryant, Edgeworth, Austen, Whitman, Milton, Melville, Carroll, Shakespeare, and Burgess.\n",
        "After labeling, two sets of features were created using bag of words and TF-IDF.\n",
        "Both sets of features were reduced using singular value decomposition to reduce computational complexity and remove noise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZAZFpurWX4D",
        "colab_type": "text"
      },
      "source": [
        "### Import Packages and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2JB1cpGhvBh",
        "colab_type": "code",
        "outputId": "a15b6cea-1f27-4c13-e4fa-15ebc6897ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "!python -m spacy download en\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "import textwrap\n",
        "from nltk.corpus import gutenberg\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Suppress Warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    action=\"ignore\"  \n",
        "    )\n",
        "\n",
        "# Display Preferences\n",
        "\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "pd.options.mode.chained_assignment = None"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "CPU times: user 727 ms, sys: 133 ms, total: 860 ms\n",
            "Wall time: 7.35 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9rKRpJXjy2-",
        "colab_type": "code",
        "outputId": "a987248d-a23c-438f-db82-2c0988fcc12f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Import Files and Process the Raw Data.\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "brown = gutenberg.raw('chesterton-brown.txt')\n",
        "stories = gutenberg.raw('bryant-stories.txt')\n",
        "parents = gutenberg.raw('edgeworth-parents.txt')\n",
        "emma = gutenberg.raw('austen-emma.txt')\n",
        "leaves = gutenberg.raw('whitman-leaves.txt')\n",
        "paradise = gutenberg.raw('milton-paradise.txt')\n",
        "moby_dick = gutenberg.raw('melville-moby_dick.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "busterbrown = gutenberg.raw('burgess-busterbrown.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "CPU times: user 4.25 ms, sys: 5.02 ms, total: 9.26 ms\n",
            "Wall time: 10.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ_vgnNjWts9",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aki777w6oCJF",
        "colab_type": "code",
        "outputId": "d5ab1f33-7841-4170-acee-6ae96b2306dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Clean text data\n",
        "\n",
        "def text_cleaner(text):\n",
        "    # Visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  Better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "brown = text_cleaner(brown[:60000])\n",
        "stories = text_cleaner(stories[:60000])\n",
        "parents = text_cleaner(parents[:60000])\n",
        "emma = text_cleaner(emma[:60000])\n",
        "leaves = text_cleaner(leaves[:60000])\n",
        "paradise = text_cleaner(paradise[:60000])\n",
        "moby_dick = text_cleaner(moby_dick[:60000])\n",
        "alice = text_cleaner(alice[:60000])\n",
        "hamlet = text_cleaner(hamlet[:60000])\n",
        "busterbrown = text_cleaner(busterbrown[:60000])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.69 ms, sys: 3.95 ms, total: 10.6 ms\n",
            "Wall time: 10.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxizoAJvoUyc",
        "colab_type": "code",
        "outputId": "80192a2f-9a7d-4f64-ea7d-fb0452b0a043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Extract ~ 100 Excerpts Each from All Texts, Totaling ~ 1000 Excerpts to Be Processed\n",
        "\n",
        "all_texts = [ \n",
        "brown, stories, parents, emma,\n",
        "leaves, paradise, moby_dick,\n",
        "alice, hamlet, busterbrown\n",
        "]\n",
        "\n",
        "cleaned_excerpts = []\n",
        "for texts in all_texts:\n",
        "  cleaned_excerpts.append(textwrap.wrap(texts, len(texts)// 100))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 158 ms, sys: 1.53 ms, total: 160 ms\n",
            "Wall time: 160 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-Sut44om-T",
        "colab_type": "code",
        "outputId": "444300ec-5656-4e56-9607-93c913108333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Parse the cleaned excerpts\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "parsed_excerpts = []\n",
        "for excerpts in cleaned_excerpts:\n",
        "  single_text = []\n",
        "  for excerpt in excerpts:\n",
        "    single_text.append(nlp(excerpt))\n",
        "  parsed_excerpts.append(single_text)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.7 s, sys: 262 ms, total: 24 s\n",
            "Wall time: 24.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1zbHktSpPzd",
        "colab_type": "code",
        "outputId": "597ad56a-743c-40ee-f34e-30f2b57d879d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Convert Excerpts into Strings and Load them into Dataframes\n",
        "\n",
        "all_sents = []\n",
        "for excerpts in parsed_excerpts:\n",
        "  single_text = []\n",
        "  for excerpt in excerpts:\n",
        "    single_text.append(str(excerpt))\n",
        "  all_sents.append(pd.DataFrame(single_text).applymap(str).apply(lambda x: x + ' '))\n",
        "  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 113 ms, sys: 1.05 ms, total: 114 ms\n",
            "Wall time: 127 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zPes2WApTY7",
        "colab_type": "code",
        "outputId": "c33f48a3-90b9-4699-ca6a-790bd3df4b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Assign Authors to Excerpts\n",
        "\n",
        "author_names = [\n",
        "\"chesterton\",\n",
        "\"bryant\",\n",
        "\"edgeworth\",\n",
        "\"austen\",\n",
        "\"whitman\",\n",
        "\"milton\",\n",
        "\"melville\",\n",
        "\"carroll\",\n",
        "\"shakespeare\",\n",
        "\"burgess\"\n",
        "]\n",
        "\n",
        "for index_number in list(range(0,10)):\n",
        "  all_sents[index_number]['author'] = author_names[index_number]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6.57 ms, sys: 41 µs, total: 6.62 ms\n",
            "Wall time: 7.35 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQw87OCqpTEL",
        "colab_type": "code",
        "outputId": "fed3a1f8-1a43-4c01-f3d0-fd09556e4efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Load Labeled Excerpts into single DataFrame\n",
        "\n",
        "labeled_excerpts = pd.concat(all_sents)\n",
        "\n",
        "print(labeled_excerpts.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   0      author\n",
            "0  I. The Absence of Mr Glass THE consulting-room...  chesterton\n",
            "1  poetry. These things were there, in their plac...  chesterton\n",
            "2  room was lined with as complete a set of Engli...  chesterton\n",
            "3  ballads and the tables laden with drink and to...  chesterton\n",
            "4  shot with grey, but growing thick and healthy;...  chesterton\n",
            "CPU times: user 14.2 ms, sys: 987 µs, total: 15.2 ms\n",
            "Wall time: 14.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K73RRc0gQtf",
        "colab_type": "text"
      },
      "source": [
        "## Data Exploration and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqDDIiUygQtf",
        "colab_type": "code",
        "outputId": "2c5240d6-b4a0-4855-c3bf-3f1d7e337001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "for sents in all_sents:\n",
        "  print(sents.iloc[1,1] + ':\\n' + sents.iloc[1,0] + '\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chesterton:\n",
            "poetry. These things were there, in their place; but one felt that they were never allowed out of their place. Luxury was there: there stood upon a special table eight or ten boxes of the best cigars; but they were built upon a plan so that the strongest were always nearest the wall and the mildest nearest the window. A tantalus containing three kinds of spirit, all of a liqueur excellence, stood always on this table of luxury; but the fanciful have asserted that the whisky, brandy, and rum seemed always to stand at the same level. Poetry was there: the left-hand corner of the \n",
            "\n",
            "bryant:\n",
            "\"It's the Rain, and I want to come in,\" said a soft, sad, little voice. \"No, you can't come in,\" the little Tulip said. By and by she heard another little _tap, tap, tap_ on the window-pane. \"Who is there?\" she said. The same soft little voice answered, \"It's the Rain, and I want to come in!\" \"No, you can't come in,\" said the little Tulip. Then it was very still for a long time. At last, there came a little rustling, whispering sound, all round the window: _rustle, whisper, whisper_. \"Who is there?\" said the little Tulip. \"It's the Sunshine,\" said a little, \n",
            "\n",
            "edgeworth:\n",
            "gathered round the fire eating their potatoes and milk for supper. \"Bless them, the poor young creatures!\" said the widow, who, as she lay on her bed, which she knew must be her deathbed, was thinking of what would become of her children after she was gone. Mary stopped her wheel, for she was afraid that the noise of it had wakened her mother, and would hinder her from going to sleep again. \"No need to stop the wheel, Mary, dear, for me,\" said her mother, \"I was not asleep; nor is it THAT which keeps me from sleep. But don't overwork yourself, Mary.\" \"Oh, no fear of that,\" \n",
            "\n",
            "austen:\n",
            "woman as governess, who had fallen little short of a mother in affection. Sixteen years had Miss Taylor been in Mr. Woodhouse's family, less as a governess than a friend, very fond of both daughters, but particularly of Emma. Between _them_ it was more the intimacy of sisters. Even before Miss Taylor had ceased to hold the nominal office of governess, the mildness of her temper had hardly allowed her to impose any restraint; and the shadow of authority being now long passed away, they had been living together as friend and friend very mutually attached, and Emma doing just what she liked; \n",
            "\n",
            "whitman:\n",
            "alone nor brain alone is worthy for the Muse, I say the Form complete is worthier far, The Female equally with the Male I sing. Of Life immense in passion, pulse, and power, Cheerful, for freest action form'd under the laws divine, The Modern Man I sing. } As I Ponder'd in Silence As I ponder'd in silence, Returning upon my poems, considering, lingering long, A Phantom arose before me with distrustful aspect, Terrible in beauty, age, and power, The genius of poets of old lands, As to me directing like flame its eyes, With finger pointing to many immortal songs, And menacing \n",
            "\n",
            "milton:\n",
            "intends to soar Above th' Aonian mount, while it pursues Things unattempted yet in prose or rhyme. And chiefly thou, O Spirit, that dost prefer Before all temples th' upright heart and pure, Instruct me, for thou know'st; thou from the first Wast present, and, with mighty wings outspread, Dove-like sat'st brooding on the vast Abyss, And mad'st it pregnant: what in me is dark Illumine, what is low raise and support; That, to the height of this great argument, I may assert Eternal Providence, And justify the ways of God to men. Say first for Heaven hides nothing from thy view, \n",
            "\n",
            "melville:\n",
            "the signification of the word, you deliver that which is not true.\" HACKLUYT \"WHALE. ... Sw. and Dan. HVAL. This animal is named from roundness or rolling; for in Dan. HVALT is arched or vaulted.\" WEBSTER'S DICTIONARY \"WHALE. ... It is more immediately from the Dut. and Ger. WALLEN; A.S. WALW-IAN, to roll, to wallow.\" RICHARDSON'S DICTIONARY KETOS, GREEK. CETUS, LATIN. WHOEL, ANGLO-SAXON. HVALT, DANISH. WAL, DUTCH. HWAL, SWEDISH. WHALE, ICELANDIC. WHALE, ENGLISH. BALEINE, FRENCH. BALLENA, SPANISH. PEKEE-NUEE-NUEE, FEGEE. PEKEE-NUEE-NUEE, ERROMANGOAN. EXTRACTS (Supplied by \n",
            "\n",
            "carroll:\n",
            "Rabbit with pink eyes ran close by her. There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear! Oh dear! I shall be late!' (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually TOOK A WATCH OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat- \n",
            "\n",
            "shakespeare:\n",
            "heare them. Stand: who's there? Hor. Friends to this ground Mar. And Leige-men to the Dane Fran. Giue you good night Mar. O farwel honest Soldier, who hath relieu'd you? Fra. Barnardo ha's my place: giue you goodnight. Exit Fran. Mar. Holla Barnardo Bar. Say, what is Horatio there? Hor. A peece of him Bar. Welcome Horatio, welcome good Marcellus Mar. What, ha's this thing appear'd againe to night Bar. I haue seene nothing Mar. Horatio saies, 'tis but our Fantasie, And will not let beleefe take hold of him Touching this dreaded sight, twice seene of vs, Therefore I haue \n",
            "\n",
            "burgess:\n",
            "trying to make up his mind what would taste best, he was listening to the sounds that told of the waking of all the little people who live in the Green Forest. He heard Sammy Jay way off in the distance screaming, \"Thief! Thief!\" and grinned. \"I wonder,\" thought Buster, \"if some one has stolen Sammy's breakfast, or if he has stolen the breakfast of some one else. Probably he is the thief himself.\" He heard Chatterer the Red Squirrel scolding as fast as he could make his tongue go and working himself into a terrible rage. \"Must be that Chatterer got out of bed the wrong way \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GayQh_BugQti",
        "colab_type": "text"
      },
      "source": [
        "## Unsupervised Feature Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_W4qmhwV3Vf-",
        "outputId": "330cf1a1-a1be-41f4-8dc3-852d316edc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Vectorizing Text Data \n",
        "\n",
        "# Using Porter Stemmer\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stemming_tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "  \n",
        "\n",
        "# Using TfIdf\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, max_features=1500, use_idf=True)\n",
        "X = tfidf_vectorizer.fit_transform(labeled_excerpts.iloc[:,0])\n",
        "df_tfidf = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
        "\n",
        "# View Shape of TfIdf Matrix\n",
        "\n",
        "print(df_tfidf.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1010, 1500)\n",
            "CPU times: user 1.61 s, sys: 8.92 ms, total: 1.62 s\n",
            "Wall time: 1.64 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4EXlZ2PZv4E",
        "colab_type": "code",
        "outputId": "3ac08bca-aa35-465d-8f2c-2bed7c8c3ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "labeled_excerpts.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 575 µs, sys: 10 µs, total: 585 µs\n",
            "Wall time: 525 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I. The Absence of Mr Glass THE consulting-room...</td>\n",
              "      <td>chesterton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>poetry. These things were there, in their plac...</td>\n",
              "      <td>chesterton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>room was lined with as complete a set of Engli...</td>\n",
              "      <td>chesterton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ballads and the tables laden with drink and to...</td>\n",
              "      <td>chesterton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>shot with grey, but growing thick and healthy;...</td>\n",
              "      <td>chesterton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0      author\n",
              "0  I. The Absence of Mr Glass THE consulting-room...  chesterton\n",
              "1  poetry. These things were there, in their plac...  chesterton\n",
              "2  room was lined with as complete a set of Engli...  chesterton\n",
              "3  ballads and the tables laden with drink and to...  chesterton\n",
              "4  shot with grey, but growing thick and healthy;...  chesterton"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLAKCDutZcan",
        "colab_type": "code",
        "outputId": "22c66159-0c37-4e02-e658-92ee0050470f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "df_tfidf.head(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abl</th>\n",
              "      <th>abov</th>\n",
              "      <th>absenc</th>\n",
              "      <th>accept</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>acorn</th>\n",
              "      <th>acquaint</th>\n",
              "      <th>act</th>\n",
              "      <th>activ</th>\n",
              "      <th>actual</th>\n",
              "      <th>ad</th>\n",
              "      <th>address</th>\n",
              "      <th>admir</th>\n",
              "      <th>admit</th>\n",
              "      <th>advanc</th>\n",
              "      <th>advantag</th>\n",
              "      <th>advic</th>\n",
              "      <th>advis</th>\n",
              "      <th>affect</th>\n",
              "      <th>afford</th>\n",
              "      <th>afraid</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>afterward</th>\n",
              "      <th>age</th>\n",
              "      <th>agent</th>\n",
              "      <th>ago</th>\n",
              "      <th>agre</th>\n",
              "      <th>ah</th>\n",
              "      <th>ahead</th>\n",
              "      <th>ain</th>\n",
              "      <th>air</th>\n",
              "      <th>ala</th>\n",
              "      <th>alic</th>\n",
              "      <th>allow</th>\n",
              "      <th>alon</th>\n",
              "      <th>aloud</th>\n",
              "      <th>alreadi</th>\n",
              "      <th>altar</th>\n",
              "      <th>altogeth</th>\n",
              "      <th>...</th>\n",
              "      <th>wide</th>\n",
              "      <th>widow</th>\n",
              "      <th>wife</th>\n",
              "      <th>wild</th>\n",
              "      <th>william</th>\n",
              "      <th>wind</th>\n",
              "      <th>window</th>\n",
              "      <th>wine</th>\n",
              "      <th>wing</th>\n",
              "      <th>wink</th>\n",
              "      <th>winter</th>\n",
              "      <th>wise</th>\n",
              "      <th>wish</th>\n",
              "      <th>wit</th>\n",
              "      <th>woe</th>\n",
              "      <th>wolf</th>\n",
              "      <th>woman</th>\n",
              "      <th>women</th>\n",
              "      <th>won</th>\n",
              "      <th>wonder</th>\n",
              "      <th>wont</th>\n",
              "      <th>wood</th>\n",
              "      <th>woodhous</th>\n",
              "      <th>word</th>\n",
              "      <th>work</th>\n",
              "      <th>world</th>\n",
              "      <th>wors</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>wouldn</th>\n",
              "      <th>wound</th>\n",
              "      <th>wretch</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>ye</th>\n",
              "      <th>year</th>\n",
              "      <th>yell</th>\n",
              "      <th>yellow</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.148</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.209</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    abl  abov  absenc  accept  accord  ...  year  yell  yellow  young  youth\n",
              "0 0.000 0.000   0.194   0.000   0.000  ... 0.000 0.000   0.000  0.000  0.000\n",
              "1 0.000 0.000   0.000   0.000   0.000  ... 0.000 0.000   0.000  0.000  0.000\n",
              "2 0.000 0.000   0.209   0.000   0.000  ... 0.000 0.000   0.000  0.000  0.000\n",
              "3 0.000 0.000   0.000   0.000   0.000  ... 0.000 0.000   0.000  0.000  0.000\n",
              "4 0.000 0.000   0.000   0.000   0.000  ... 0.000 0.000   0.000  0.000  0.000\n",
              "\n",
              "[5 rows x 1500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB8snBScgQt5",
        "colab_type": "text"
      },
      "source": [
        "## Creating Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWQmA3oWgQt5",
        "colab_type": "code",
        "outputId": "433a7f4c-95b7-4137-91b3-72caad970ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Select a text to create recommendations for\n",
        "\n",
        "# Text Was Selected Using Index From Labeled Excerpts DataFrame\n",
        "test_text = labeled_excerpts.iloc[2,:]\n",
        "\n",
        "print('\\n' + test_text[0][:100] + '\\n' + test_text[0][100:200] + '\\n' + test_text[0][200:300] + '\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "room was lined with as complete a set of English classics as the right hand could show of English an\n",
            "d foreign physiologists. But if one took a volume of Chaucer or Shelley from that rank, its absence \n",
            "irritated the mind like a gap in a man's front teeth. One could not say the books were never read; p\n",
            "\n",
            "CPU times: user 794 µs, sys: 0 ns, total: 794 µs\n",
            "Wall time: 706 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eyto_45voUE",
        "colab_type": "code",
        "outputId": "b7a7cbff-a35f-46d2-bb6f-a371bc3477b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Transform the text to tokens based on the vectorizer used for the original data\n",
        "\n",
        "test_tfidf = tfidf_vectorizer.transform([test_text[0]])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4.63 ms, sys: 0 ns, total: 4.63 ms\n",
            "Wall time: 6.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnbXM4XCvoBk",
        "colab_type": "code",
        "outputId": "b5c357b2-a012-4faf-eb93-7eb2160f153d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Compute cos similarity between test text and the rest of the documents\n",
        "\n",
        "cos_similarity_tfidf = map(lambda x: cosine_similarity(test_tfidf, x),X)\n",
        "results = list(cos_similarity_tfidf)\n",
        "results = [[x][0][0][0] for x in results]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 586 ms, sys: 0 ns, total: 586 ms\n",
            "Wall time: 591 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjaaO7SO5AJi",
        "colab_type": "code",
        "outputId": "a64b75d9-fe3b-4158-807d-10637f609750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Create a dataframe for text recommendations\n",
        "\n",
        "test_text_recommendations = labeled_excerpts.reset_index(drop=True)\n",
        "test_text_recommendations.loc[:,'test_recommendation'] = results\n",
        "test_text_recommendations = test_text_recommendations.sort_values(by=['test_recommendation'], ascending=0, axis=0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.26 ms, sys: 0 ns, total: 3.26 ms\n",
            "Wall time: 3.65 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePrIHZWHltG3",
        "colab_type": "code",
        "outputId": "4eae2b97-60ce-410b-999d-25d32f425a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Display Top 10 Recommendations\n",
        "\n",
        "test_text_recommendations.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 495 µs, sys: 12 µs, total: 507 µs\n",
            "Wall time: 504 µs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>author</th>\n",
              "      <th>test_recommendation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>room was lined with as complete a set of Engli...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ballads and the tables laden with drink and to...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>cloudy ideals or cloudy compromises of the nor...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I. The Absence of Mr Glass THE consulting-room...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>nigh the tail, and, like a restless needle soj...</td>\n",
              "      <td>melville</td>\n",
              "      <td>0.191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>and foot, and parks of artillery, And artiller...</td>\n",
              "      <td>whitman</td>\n",
              "      <td>0.183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bobbing bow over it, as if setting everything ...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>with great attention. The brigand captain took...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>the English, no nobler crests or chasms than t...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>as to send Mrs. Goddard a beautiful goose the ...</td>\n",
              "      <td>austen</td>\n",
              "      <td>0.141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0  ... test_recommendation\n",
              "2    room was lined with as complete a set of Engli...  ...               1.000\n",
              "3    ballads and the tables laden with drink and to...  ...               0.289\n",
              "57   cloudy ideals or cloudy compromises of the nor...  ...               0.220\n",
              "0    I. The Absence of Mr Glass THE consulting-room...  ...               0.198\n",
              "683  nigh the tail, and, like a restless needle soj...  ...               0.191\n",
              "427  and foot, and parks of artillery, And artiller...  ...               0.183\n",
              "7    bobbing bow over it, as if setting everything ...  ...               0.163\n",
              "92   with great attention. The brigand captain took...  ...               0.154\n",
              "77   the English, no nobler crests or chasms than t...  ...               0.141\n",
              "377  as to send Mrs. Goddard a beautiful goose the ...  ...               0.141\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWUfbqcb_TDJ",
        "colab_type": "code",
        "outputId": "36a4cc03-e4f4-45d3-e716-f20f615be667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "list(test_text_recommendations.iloc[:,0][:5])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"room was lined with as complete a set of English classics as the right hand could show of English and foreign physiologists. But if one took a volume of Chaucer or Shelley from that rank, its absence irritated the mind like a gap in a man's front teeth. One could not say the books were never read; probably they were, but there was a sense of their being chained to their places, like the Bibles in the old churches. Dr Hood treated his private book-shelf as if it were a public library. And if this strict scientific intangibility steeped even the shelves laden with lyrics and \",\n",
              " \"ballads and the tables laden with drink and tobacco, it goes without saying that yet more of such heathen holiness protected the other shelves that held the specialist's library, and the other tables that sustained the frail and even fairylike instruments of chemistry or mechanics. Dr Hood paced the length of his string of apartments, bounded as the boys' geographies say on the east by the North Sea and on the west by the serried ranks of his sociological and criminologist library. He was clad in an artist's velvet, but with none of an artist's negligence; his hair was heavily \",\n",
              " \"cloudy ideals or cloudy compromises of the north; to vaguer races his intensity smelt of danger or even crime. Like fire or the sea, he was too simple to be trusted. The banker and his beautiful English daughter were staying at the hotel attached to Muscari's restaurant; that was why it was his favourite restaurant. A glance flashed around the room told him at once, however, that the English party had not descended. The restaurant was glittering, but still comparatively empty. Two priests were talking at a table in a corner, but Muscari (an ardent Catholic) took no more notice of \",\n",
              " \"I. The Absence of Mr Glass THE consulting-rooms of Dr Orion Hood, the eminent criminologist and specialist in certain moral disorders, lay along the sea-front at Scarborough, in a series of very large and well-lighted french windows, which showed the North Sea like one endless outer wall of blue-green marble. In such a place the sea had something of the monotony of a blue-green dado: for the chambers themselves were ruled throughout by a terrible tidiness not unlike the terrible tidiness of the sea. It must not be supposed that Dr Hood's apartments excluded luxury, or even \",\n",
              " \"nigh the tail, and, like a restless needle sojourning in the body of a man, travelled full forty feet, and at last was found imbedded in the hump. Crossing this dusky entry, and on through yon low-arched way cut through what in old times must have been a great central chimney with fireplaces all round you enter the public room. A still duskier place is this, with such low ponderous beams above, and such old wrinkled planks beneath, that you would almost fancy you trod some old craft's cockpits, especially of such a howling night, when this corner-anchored old ark rocked so \"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew8_L7iDgQt7",
        "colab_type": "text"
      },
      "source": [
        "## Analysis and Evaluation of Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcc_xDhigQt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUw5CRDngQt-",
        "colab_type": "text"
      },
      "source": [
        "## Final Modeling Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JtcJ5tMgQt_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRw58gGvgQuB",
        "colab_type": "code",
        "outputId": "4b48d22e-e98c-437d-f0ae-b8652831263e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_text_recommendations"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>author</th>\n",
              "      <th>test_recommendation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>room was lined with as complete a set of Engli...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ballads and the tables laden with drink and to...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>cloudy ideals or cloudy compromises of the nor...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I. The Absence of Mr Glass THE consulting-room...</td>\n",
              "      <td>chesterton</td>\n",
              "      <td>0.198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>683</th>\n",
              "      <td>nigh the tail, and, like a restless needle soj...</td>\n",
              "      <td>melville</td>\n",
              "      <td>0.191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>832</th>\n",
              "      <td>Incestuous sheets: It is not, nor it cannot co...</td>\n",
              "      <td>shakespeare</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>righteous, I make appointments with all, I wil...</td>\n",
              "      <td>whitman</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>potato to put into my mouth! I, that have been...</td>\n",
              "      <td>edgeworth</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>or what more lost in Hell?\" So Satan spake; an...</td>\n",
              "      <td>milton</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>affections, They scorn the best I can do to re...</td>\n",
              "      <td>whitman</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1010 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     0  ... test_recommendation\n",
              "2    room was lined with as complete a set of Engli...  ...               1.000\n",
              "3    ballads and the tables laden with drink and to...  ...               0.289\n",
              "57   cloudy ideals or cloudy compromises of the nor...  ...               0.220\n",
              "0    I. The Absence of Mr Glass THE consulting-room...  ...               0.198\n",
              "683  nigh the tail, and, like a restless needle soj...  ...               0.191\n",
              "..                                                 ...  ...                 ...\n",
              "832  Incestuous sheets: It is not, nor it cannot co...  ...               0.000\n",
              "504  righteous, I make appointments with all, I wil...  ...               0.000\n",
              "278  potato to put into my mouth! I, that have been...  ...               0.000\n",
              "525  or what more lost in Hell?\" So Satan spake; an...  ...               0.000\n",
              "489  affections, They scorn the best I can do to re...  ...               0.000\n",
              "\n",
              "[1010 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbC1z4MtQz_c",
        "colab_type": "text"
      },
      "source": [
        "### Batch Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mIdmqqX6Szy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import linear_kernel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tmzl6uzjgQuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_similarities = linear_kernel(df_tfidf, df_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEy9HtNZgQuF",
        "colab_type": "code",
        "outputId": "5885283f-4fbe-458c-ff37-4bd5c4cc6594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "cosine_similarities"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.16154482, 0.19772786, ..., 0.        , 0.01794152,\n",
              "        0.03803436],\n",
              "       [0.16154482, 1.        , 0.05019935, ..., 0.01772728, 0.00891493,\n",
              "        0.01057863],\n",
              "       [0.19772786, 0.05019935, 1.        , ..., 0.02195751, 0.03157508,\n",
              "        0.01097119],\n",
              "       ...,\n",
              "       [0.        , 0.01772728, 0.02195751, ..., 1.        , 0.38400856,\n",
              "        0.05550186],\n",
              "       [0.01794152, 0.00891493, 0.03157508, ..., 0.38400856, 1.        ,\n",
              "        0.02839026],\n",
              "       [0.03803436, 0.01057863, 0.01097119, ..., 0.05550186, 0.02839026,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJEBfwRrgQuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = labeled_excerpts.iterrows()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6mby64rQy6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrHkHYatgQuK",
        "colab_type": "code",
        "outputId": "e1b61bcb-aaba-47fe-9729-629b50f42aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "next(r)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0         I. The Absence of Mr Glass THE consulting-room...\n",
              " author                                           chesterton\n",
              " Name: 0, dtype: object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rwFgptVgQuO",
        "colab_type": "code",
        "outputId": "35117d16-8d9d-4c96-e6c6-9b921ba3c3e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "labeled_excerpts.sort_values(by=['test_recommendation'], ascending=0, axis=0)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-7883530e64ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabeled_excerpts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_recommendation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index)\u001b[0m\n\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4927\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'test_recommendation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAV3nIaagQuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE1uUT3xgQuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bcCVg1yE57C_"
      },
      "source": [
        "## Analysis and Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QyoS8AY0Lg0D"
      },
      "source": [
        "Both classification and clustering were able to reliably label the excerpts by author in this study.\n",
        "The neural network built on TF-IDF features, the best performing model, had over a 95% accuracy and regularly labeled each author's excerpts correctly over 80% of the time.\n",
        "Clustering was able to yield high accuracy as well, grouping over 80% of each author's excerpts together with the exception of Melville's excerpts. Melville's excerpts was consistently the least consistently labeled across all models, implying that discrepancies in its labeling are due to the data itsself rather than the method of feature preparation and classification. \n",
        "Modeling did have the advantage of being more accurate but clustering was able to show strong reliability even in the abscence of labels.\n",
        "\n",
        "This established the relative ability of clustering and modeling unsupervised learning generated features to classify the authors of writing samples.\n",
        "By being able to reliably label data using unsupervised and supervised methods, large amounts of text can be analyzed, even in the abscence of pre-established labels. A condition often found in real-world data.\n",
        "The next step in using this data to discern the source of the text data would be to collect more text from different authors and more data about the context in which the text was generated. Afterwards the study can be expanded to include different types of feature preparation.\n",
        "\n",
        "Understanding how to better utilize unsupervised modeling techniques to predict author, will give insight as to what kind of people are generating different types of texts. \n",
        "This can be practically be applied to consumer data such as reviews and other types of user generated text.\n",
        "This can allow for more direct marketing to users or changes in products that better match how services are used. \n",
        "Being able to utilize readily available data that isn't always processed and labeled, allows for revenue generating decisions to be made at very little cost to stakeholders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P0HkGW7mNpFX",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}