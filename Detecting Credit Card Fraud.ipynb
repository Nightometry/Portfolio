{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Analysis of the Ability of Multiple Supervised Learning Classification Models to Detect Credit Card Fraud\n",
    "<br>\n",
    "<br>\n",
    "The incidence of credit card fraud reached an all time high in 2016 with 15.4 million people affected and $16 billion in fraud losses.\n",
    "To better understand how to address this problem, I am interested in credit card fraud prediction through supervised machine learning methods.\n",
    "There are various ways authentication systems are bypassed or exploited that allow for fraud to be committed.\n",
    "As a result, the damage is still in the billions despite consistently increasing security measures.\n",
    "The liability for these huges losses usually fall on the banks that are involved and can be passed on to the institutions where the fraud occurred.\n",
    "With supervised learning, credit card fraud can be predicted using underlying factors that aren't readily interpereted by human logic alone.\n",
    "This means of detecting credit card fraud provides a proactive means of combating this trend and preventing large financial losses. \n",
    "\n",
    "\n",
    "In this study, several different types of supervised learning classification models were used on the same labeled financial data to analyze their compared effectiveness when it comes to predicting credit card fraud. \n",
    "In addition to this each model type was run three times using different methods to prepare the feature variables. \n",
    "This gave insight as to which types of models and feature engineering methods were best suited to predict creditcard fraud based on the data. \n",
    "The process used to undertake this study is as follows:\n",
    "<br>\n",
    "<br>\n",
    "Data Exploration and Analysis \n",
    "* Viewing the Distribution of the Datapoints\n",
    "* Checking the Correlatedness of the Classes\n",
    "* Descriptive Statistics\n",
    "\n",
    "Preparing The Data For Modeling\n",
    "* Dealing With Class Imbalance\n",
    "* Select K Best\n",
    "* Splitting training and testing data\n",
    "\n",
    "\n",
    "Modeling the Data \n",
    "* Na√Øve Bayes\n",
    "* K Nearest Neighbors\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* Logistic Regression (and Lasso and Ridge)\n",
    "* Support Vector Classifier\n",
    "* Gradient Boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages and CSV\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import resample\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"sklearn\"  \n",
    "    )\n",
    "\n",
    "# Set Plot Style\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Files\n",
    "\n",
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Analysis\n",
    "\n",
    "Dataset comes from European Credit Card transactions taken over the course of two days in September 2013. \n",
    "The dataset contains 28 components that are the result of transformation through principal components analysis.\n",
    "To maintain the confidentiality of the accountholders, the original features weren't used for this study. The three features that were not transformed were: The time the transactions took place relative to the start of the study, the dollar amount involved in each transaction, and labels to denote instances of fraud.\n",
    "This allows for the understanding of fraud occurence in relation to cost and time of day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.360</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1.378</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.278</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.129</td>\n",
       "      <td>-0.189</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>149.620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.192</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.060</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.085</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>-0.639</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.126</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.015</td>\n",
       "      <td>2.690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.358</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>1.773</td>\n",
       "      <td>0.380</td>\n",
       "      <td>-0.503</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.248</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.909</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.328</td>\n",
       "      <td>-0.139</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>378.660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>-0.185</td>\n",
       "      <td>1.793</td>\n",
       "      <td>-0.863</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>1.247</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-1.176</td>\n",
       "      <td>0.647</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.061</td>\n",
       "      <td>123.500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.000</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.549</td>\n",
       "      <td>0.403</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>0.818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.798</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.215</td>\n",
       "      <td>69.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.961</td>\n",
       "      <td>1.141</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.421</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208</td>\n",
       "      <td>-0.560</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.081</td>\n",
       "      <td>3.670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.000</td>\n",
       "      <td>1.230</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.045</td>\n",
       "      <td>1.203</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.273</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>-0.780</td>\n",
       "      <td>0.750</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4.990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time     V1     V2    V3     V4     V5     V6     V7     V8     V9  ...  \\\n",
       "0 0.000 -1.360 -0.073 2.536  1.378 -0.338  0.462  0.240  0.099  0.364  ...   \n",
       "1 0.000  1.192  0.266 0.166  0.448  0.060 -0.082 -0.079  0.085 -0.255  ...   \n",
       "2 1.000 -1.358 -1.340 1.773  0.380 -0.503  1.800  0.791  0.248 -1.515  ...   \n",
       "3 1.000 -0.966 -0.185 1.793 -0.863 -0.010  1.247  0.238  0.377 -1.387  ...   \n",
       "4 2.000 -1.158  0.878 1.549  0.403 -0.407  0.096  0.593 -0.271  0.818  ...   \n",
       "5 2.000 -0.426  0.961 1.141 -0.168  0.421 -0.030  0.476  0.260 -0.569  ...   \n",
       "6 4.000  1.230  0.141 0.045  1.203  0.192  0.273 -0.005  0.081  0.465  ...   \n",
       "\n",
       "     V21    V22    V23    V24    V25    V26    V27    V28  Amount  Class  \n",
       "0 -0.018  0.278 -0.110  0.067  0.129 -0.189  0.134 -0.021 149.620      0  \n",
       "1 -0.226 -0.639  0.101 -0.340  0.167  0.126 -0.009  0.015   2.690      0  \n",
       "2  0.248  0.772  0.909 -0.689 -0.328 -0.139 -0.055 -0.060 378.660      0  \n",
       "3 -0.108  0.005 -0.190 -1.176  0.647 -0.222  0.063  0.061 123.500      0  \n",
       "4 -0.009  0.798 -0.137  0.141 -0.206  0.502  0.219  0.215  69.990      0  \n",
       "5 -0.208 -0.560 -0.026 -0.371 -0.233  0.106  0.254  0.081   3.670      0  \n",
       "6 -0.168 -0.271 -0.154 -0.780  0.750 -0.257  0.035  0.005   4.990      0  \n",
       "\n",
       "[7 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting Histograms for the Transaction Frequencies and amounts over the two day span\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(df.Time/86400)\n",
    "plt.title(\"Transaction Frequency\")\n",
    "plt.xlabel(\"Days after start of Data Collection\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(df.Amount, bins=[0, 100, 200, 300, 400, 500, 600, 700, 800])\n",
    "plt.title(\"Transaction Amounts\")\n",
    "plt.xlabel(\"Transaction Amounts (Dollars)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transactions show a binomial distribution with a lower amount of transactions occuring at  the start of each day, and peaking about three quarters into a given day. Around peak hours the number of transactions could reach 40000.\n",
    "However, the vast majority of transaction amounts are below $100 and the number of transactions drop drastically as amount increases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Visualizing the Correlatedness of the variables\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))         \n",
    "sns.heatmap(df.corr(), cmap='RdBu_r', center=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA components are inherently uncorrelated but since the time, amount and class variables weren't converted they still show low to mild correlation with the components and eachother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   284807.000\n",
       "mean        88.350\n",
       "std        250.120\n",
       "min          0.000\n",
       "25%          5.600\n",
       "50%         22.000\n",
       "75%         77.165\n",
       "max      25691.160\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Amount.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics about the transaction amounts show that 75% of the transactions in the two day period fall below \\\\$77. However, transaction amounts can reach much higher numbers with the max being \\\\$25,691."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " The number of non-fraudulent transactions: 284315\n",
      " The number of non-fraudulent transactions: 492\n",
      " \n",
      " The percentage of non-fraudulent transactions: 0.9982725143693799\n",
      " The percentage of non-fraudulent transactions: 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "\n",
    "number_outcome_class = df.Class.value_counts()\n",
    "percent_outcome_class = df.Class.value_counts()/df.Class.value_counts().sum()\n",
    "\n",
    "print(\" \\n The number of non-fraudulent transactions: \" + str(number_outcome_class[0]))\n",
    "print(\" The number of non-fraudulent transactions: \" + str(number_outcome_class[1]))\n",
    "print(\" \\n The percentage of non-fraudulent transactions: \" + str(percent_outcome_class[0]))\n",
    "print(\" The percentage of non-fraudulent transactions: \" + str(percent_outcome_class[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transactions were overwhelmingly nonfraudulent.\n",
    "The strong class imbalance caused by the dominant negative class was addressed prior to modeling through resampling of both classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing The Data For Modeling\n",
    "\n",
    "The class imbalance was addressed by downsampling the majority class to preserve computational performance and upsampling the minority class to avoid losing too much of the variance that the models will use as the basis of their predictions.\n",
    "\n",
    "Each Model was run using two different means of feature selection;\n",
    "the original features of the dataset and just 20 of the features selected using scikit-learn's select K best function.\n",
    "The Models were run using the same training and testing sets so that they can be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2500\n",
       "0    2500\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Class Balancing by Upsampling Minority Class\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.Class==0]\n",
    "df_minority = df[df.Class==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=2500,    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=2500,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df = pd.concat([df_majority_downsampled, df_minority_upsampled])\n",
    "\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish variables based on original components to be used for modeling\n",
    "\n",
    "x = df.drop(['Class'], axis=1)\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish variables based on select K best to be used for modeling\n",
    "\n",
    "selector = SelectKBest(f_classif, k=20)\n",
    "k_predictors = selector.fit_transform(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split Original Variables And K Selected Variables for Modeling\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)\n",
    "\n",
    "kx_train, kx_test, ky_train, ky_test = train_test_split(k_predictors, y, test_size=0.2, random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling the Data\n",
    "\n",
    "The financial data was modeled using the following techniques: \n",
    "Na√Øve Bayes,\n",
    "K Nearest Neighbors,\n",
    "Decision Trees,\n",
    "Random Forest,\n",
    "Logistic Regression (and Lasso and Ridge),\n",
    "Support Vector Classifier,\n",
    "Gradient Boost,\n",
    "Each model was evaluated using accuracy score, cross validation, cross validated AUC, a confusion matrix, and a classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.05 ms, sys: 2.28 ms, total: 8.33 ms\n",
      "Wall time: 6.32 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "bnb = BernoulliNB().fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.915\n",
      "\n",
      "cross validation:\n",
      "[0.94029851 0.89054726 0.905      0.90954774 0.90954774]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.9762235  0.94729542 0.96118447 0.98180716 0.96826359]\n",
      "\n",
      "confusion matrix:\n",
      "[[511   1]\n",
      " [ 84 404]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       512\n",
      "           1       1.00      0.83      0.90       488\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      1000\n",
      "   macro avg       0.93      0.91      0.91      1000\n",
      "weighted avg       0.93      0.92      0.91      1000\n",
      "\n",
      "CPU times: user 64.2 ms, sys: 3.86 ms, total: 68.1 ms\n",
      "Wall time: 66.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(bnb.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(bnb, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(bnb, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, bnb.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, bnb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.77 ms, sys: 1.56 ms, total: 5.33 ms\n",
      "Wall time: 3.71 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_bnb = BernoulliNB().fit(kx_train, ky_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.904\n",
      "\n",
      "cross validation:\n",
      "[0.89054726 0.895      0.9        0.92       0.91959799]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.97460317 0.96544471 0.96574519 0.96484375 0.96295547]\n",
      "\n",
      "confusion matrix:\n",
      "[[476   3]\n",
      " [ 93 428]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.99      0.91       479\n",
      "           1       0.99      0.82      0.90       521\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1000\n",
      "   macro avg       0.91      0.91      0.90      1000\n",
      "weighted avg       0.92      0.90      0.90      1000\n",
      "\n",
      "CPU times: user 41.3 ms, sys: 3.36 ms, total: 44.6 ms\n",
      "Wall time: 42.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_bnb.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_bnb, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_bnb, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_bnb.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_bnb.predict(kx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes had relatively low accuracy compared to most of the other models.\n",
    "For both versions of this model, the number of false negatives was greater.\n",
    "The cross validation showed, that overfitting was not greatly present with this model. \n",
    "Using K features resulted in lower accuracy and AUC scores.\n",
    "Since the scores of the naive bayes models didn't show signs of overfitting, the loss in accuracy from using only 20 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.72 ms, sys: 1.49 ms, total: 7.21 ms\n",
      "Wall time: 5.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.783\n",
      "\n",
      "cross validation:\n",
      "[0.70646766 0.67164179 0.655      0.71859296 0.70351759]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.81365167 0.70289281 0.70678271 0.75085911 0.7672832 ]\n",
      "\n",
      "confusion matrix:\n",
      "[[377 135]\n",
      " [ 82 406]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       512\n",
      "           1       0.75      0.83      0.79       488\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1000\n",
      "   macro avg       0.79      0.78      0.78      1000\n",
      "weighted avg       0.79      0.78      0.78      1000\n",
      "\n",
      "CPU times: user 204 ms, sys: 3.26 ms, total: 207 ms\n",
      "Wall time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(knn.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(knn, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(knn, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, knn.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.36 ms, sys: 214 ¬µs, total: 5.57 ms\n",
      "Wall time: 5.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_knn = neighbors.KNeighborsClassifier(n_neighbors=10).fit(kx_train, ky_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.774\n",
      "\n",
      "cross validation:\n",
      "[0.66666667 0.695      0.645      0.65       0.6281407 ]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.72574405 0.779998   0.69621394 0.70382612 0.69266194]\n",
      "\n",
      "confusion matrix:\n",
      "[[337 142]\n",
      " [ 84 437]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       479\n",
      "           1       0.75      0.84      0.79       521\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.78      0.77      0.77      1000\n",
      "\n",
      "CPU times: user 174 ms, sys: 2.7 ms, total: 176 ms\n",
      "Wall time: 174 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_knn.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_knn, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_knn, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_knn.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_knn.predict(kx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN had the lowest out of all of the models in general.\n",
    "For both versions of this model, the number of false positives was greater.\n",
    "The cross validation showed that overfitting had a strong presence with this model. \n",
    "Using K features resulted in lower accuracy and AUC scores.\n",
    "It's likely that the nature of this data doesn't lend itself to KNN models because there may be fraudulent and non- fraudulent transactions with similar feature ranges or classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 1.61 ms, total: 21.5 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=6,\n",
    "    max_depth=25,\n",
    "    ).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.98\n",
      "\n",
      "cross validation:\n",
      "[0.93532338 0.91044776 0.96       0.95477387 0.96482412]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.96017436 0.91524668 0.94077631 0.93036184 0.9396604 ]\n",
      "\n",
      "confusion matrix:\n",
      "[[492  20]\n",
      " [  0 488]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       512\n",
      "           1       0.96      1.00      0.98       488\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "CPU times: user 81.3 ms, sys: 2.31 ms, total: 83.6 ms\n",
      "Wall time: 82 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(decision_tree.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(decision_tree, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(decision_tree, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, decision_tree.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, decision_tree.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 ms, sys: 1.78 ms, total: 22.8 ms\n",
      "Wall time: 21 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_decision_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_features=6,\n",
    "    max_depth=25,\n",
    "    ).fit(kx_train, ky_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.981\n",
      "\n",
      "cross validation:\n",
      "[0.95024876 0.97       0.895      0.945      0.90954774]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.93318452 0.9599359  0.91826923 0.89302885 0.91761134]\n",
      "\n",
      "confusion matrix:\n",
      "[[466  13]\n",
      " [  6 515]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       479\n",
      "           1       0.98      0.99      0.98       521\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "CPU times: user 63.5 ms, sys: 3.27 ms, total: 66.8 ms\n",
      "Wall time: 64.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_decision_tree.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_decision_tree, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_decision_tree, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_decision_tree.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_decision_tree.predict(kx_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree had very high performance.\n",
    "For both versions of this model, the number of false positives was greater.\n",
    "However, the version of the decision tree with all of the features had no false negatives.\n",
    "The cross validation showed that some signs of overfitting with this model. \n",
    "Using K features resulted in greater accuracy and AUC scores.\n",
    "Despite the fact that using the 20 best features resulted in better performance, the model that used all of the features would still be preferable because minimizing false negatives falls more inline with the business objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 5}\n",
      "CPU times: user 1min 42s, sys: 531 ms, total: 1min 42s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "\n",
    "parameters = { \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy'],\n",
    "              'max_depth': list(np.arange(5, 31, 5)), \n",
    "              'min_samples_split': list(np.arange(3, 12, 2)),\n",
    "              'min_samples_leaf': list(np.arange(3, 12, 2))\n",
    "             }\n",
    "\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "rfc = GridSearchCV(rf, parameters, scoring=acc_scorer).fit(x_train,  y_train)\n",
    "\n",
    "## Show Best Parameters\n",
    "print(rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.992\n",
      "\n",
      "cross validation:\n",
      "[0.9800995  0.92537313 0.945      0.9798995  0.95979899]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.99385774 0.98023578 0.98289316 0.99595715 0.9906509 ]\n",
      "\n",
      "confusion matrix:\n",
      "[[508   4]\n",
      " [  4 484]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       512\n",
      "           1       0.99      0.99      0.99       488\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "CPU times: user 4min 58s, sys: 1.41 s, total: 4min 59s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(rfc.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(rfc, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(rfc, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, rfc.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, rfc.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 20, 'max_features': 'log2', 'min_samples_leaf': 3, 'min_samples_split': 3}\n",
      "CPU times: user 1min 26s, sys: 403 ms, total: 1min 27s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_rfc = GridSearchCV(rf, parameters, scoring=acc_scorer).fit(kx_train,  ky_train)\n",
    "\n",
    "## Show Best Parameters\n",
    "print(k_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.984\n",
      "\n",
      "cross validation:\n",
      "[0.96517413 0.985      0.95       0.95       0.94472362]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.99325397 0.98888221 0.98222155 0.97450921 0.98628543]\n",
      "\n",
      "confusion matrix:\n",
      "[[473   6]\n",
      " [ 10 511]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       479\n",
      "           1       0.99      0.98      0.98       521\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "CPU times: user 4min 14s, sys: 1.54 s, total: 4min 16s\n",
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_rfc.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_rfc, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_rfc, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_rfc.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_rfc.predict(kx_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest almost had the highest performance out of all of the models.\n",
    "The version of the decision tree with the 20 best features had more false negatives.\n",
    "The cross validation showed that few signs of overfitting with this model. \n",
    "Using K features resulted in stronger cross validated accuracy and AUC scores.\n",
    "Despite the fact that using the 20 best features resulted in better performance, the model that used all of the features would still be preferable because minimizing false negatives falls more inline with the business objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.2 ms, sys: 7.91 ms, total: 75.1 ms\n",
      "Wall time: 78.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "lr = LogisticRegression(penalty='l1' ).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.947\n",
      "\n",
      "cross validation:\n",
      "[0.9800995  0.90547264 0.93       0.94472362 0.95477387]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.99128195 0.97136913 0.9794918  0.99181322 0.9855468 ]\n",
      "\n",
      "confusion matrix:\n",
      "[[494  18]\n",
      " [ 35 453]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       512\n",
      "           1       0.96      0.93      0.94       488\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      1000\n",
      "   macro avg       0.95      0.95      0.95      1000\n",
      "weighted avg       0.95      0.95      0.95      1000\n",
      "\n",
      "CPU times: user 426 ms, sys: 92 ms, total: 518 ms\n",
      "Wall time: 141 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(lr.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(lr, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(lr, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, lr.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, lr.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.9 ms, sys: 3.1 ms, total: 32.9 ms\n",
      "Wall time: 32.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_lr = LogisticRegression(penalty='l1' ).fit(kx_train, ky_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.942\n",
      "\n",
      "cross validation:\n",
      "[0.95522388 0.94       0.94       0.95       0.93467337]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.97797619 0.96694712 0.98086939 0.98006811 0.9638664 ]\n",
      "\n",
      "confusion matrix:\n",
      "[[471   8]\n",
      " [ 50 471]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       479\n",
      "           1       0.98      0.90      0.94       521\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.95      0.94      0.94      1000\n",
      "\n",
      "CPU times: user 251 ms, sys: 55.9 ms, total: 307 ms\n",
      "Wall time: 78.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_lr.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_lr, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_lr, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_lr.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_lr.predict(kx_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression classifier had middling performance compared to the rest of the other models.\n",
    "For both versions of this model, the number of false negatives was significantly greater.\n",
    "The cross validation showed that some signs of overfitting with this model. \n",
    "Using K features resulted in lower accuracy and AUC scores.\n",
    "The model that used all of the features would be preferable due to its overall better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 555 ms, sys: 37.8 ms, total: 592 ms\n",
      "Wall time: 602 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "svc = SVC().fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.994\n",
      "\n",
      "cross validation:\n",
      "[0.84577114 0.79104478 0.815      0.8040201  0.8040201 ]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.88091936 0.82355855 0.82963185 0.82757227 0.84652315]\n",
      "\n",
      "confusion matrix:\n",
      "[[512   0]\n",
      " [  6 482]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       512\n",
      "           1       1.00      0.99      0.99       488\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "CPU times: user 599 ms, sys: 4.03 ms, total: 603 ms\n",
      "Wall time: 601 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(svc.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(svc, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(svc, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, svc.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, svc.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 454 ms, sys: 16.7 ms, total: 471 ms\n",
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_svc = SVC().fit(kx_train, ky_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.99\n",
      "\n",
      "cross validation:\n",
      "[0.77114428 0.825      0.795      0.81       0.79396985]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.82594246 0.86197917 0.8447516  0.84214744 0.84949393]\n",
      "\n",
      "confusion matrix:\n",
      "[[479   0]\n",
      " [ 10 511]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       479\n",
      "           1       1.00      0.98      0.99       521\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "CPU times: user 436 ms, sys: 5.49 ms, total: 441 ms\n",
      "Wall time: 439 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_svc.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_svc, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_svc, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_svc.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_svc.predict(kx_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector classifier had relatively low performance out of all of the models.\n",
    "The accuracy was high but crossvalided AUC scores were low which could be a sign of overfitting.\n",
    "Both versions of the support vector classifier had more false negatives than false positives.\n",
    "Using K features resulted in similar cross validated accuracy and AUC scores.\n",
    "Using support vector classifiers for this data may result in lower performance due to a lack of discrete classes relative to the types of data that may come from the transformed features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 'exponential', 'max_depth': 4, 'n_estimators': 750}\n",
      "CPU times: user 13min 56s, sys: 3.37 s, total: 13min 59s\n",
      "Wall time: 14min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "cl = ensemble.GradientBoostingClassifier()\n",
    "\n",
    "parameters = { \n",
    "              'n_estimators': list(np.arange(200, 801, 50)),\n",
    "              'max_depth': list(range(1,5)),\n",
    "              'loss': ['deviance', 'exponential']\n",
    "             }\n",
    "\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "clf = GridSearchCV(cl, parameters, scoring=acc_scorer).fit(x_train,  y_train)\n",
    "\n",
    "## Show Best Parameters\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.997\n",
      "\n",
      "cross validation:\n",
      "[0.9800995  0.93532338 0.96       0.97487437 0.95979899]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.99663166 0.99098474 0.99489796 0.99747322 0.99211643]\n",
      "\n",
      "confusion matrix:\n",
      "[[509   3]\n",
      " [  0 488]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       512\n",
      "           1       0.99      1.00      1.00       488\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "CPU times: user 28min 59s, sys: 7.67 s, total: 29min 7s\n",
      "Wall time: 29min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(clf.score(x_test, y_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(clf, x_test, y_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(clf, x_test, y_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, clf.predict(x_test)))+'\\n')\n",
    "\n",
    "print(classification_report(y_test, clf.predict(x_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 6s, sys: 2.47 s, total: 10min 9s\n",
      "Wall time: 10min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## train and fit model\n",
    "k_clf = GridSearchCV(cl, parameters, scoring=acc_scorer).fit(kx_train,  ky_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:\n",
      "0.988\n",
      "\n",
      "cross validation:\n",
      "[0.97512438 0.985      0.945      0.95       0.95477387]\n",
      "\n",
      "cross validation with AUC:\n",
      "[0.99742063 0.99589343 0.98477564 0.97175481 0.98431174]\n",
      "\n",
      "confusion matrix:\n",
      "[[473   6]\n",
      " [  6 515]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       479\n",
      "           1       0.99      0.99      0.99       521\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "CPU times: user 22min 55s, sys: 4.34 s, total: 23min\n",
      "Wall time: 23min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## Model Evaluation\n",
    "print(\"accuracy score:\\n\" + str(k_clf.score(kx_test, ky_test))+'\\n')\n",
    "\n",
    "print(\"cross validation:\\n\" + str(cross_val_score(k_clf, kx_test, ky_test, cv=5))+'\\n')\n",
    "\n",
    "print(\"cross validation with AUC:\\n\" + str(cross_val_score(k_clf, kx_test, ky_test, cv=5, scoring='roc_auc'))+'\\n')\n",
    "\n",
    "print(\"confusion matrix:\\n\" + str(confusion_matrix(ky_test, k_clf.predict(kx_test)))+'\\n')\n",
    "\n",
    "print(classification_report(ky_test, k_clf.predict(kx_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boost classifier had the highest performance out of all of the models.\n",
    "The version of the decision tree with the 20 best features had more false negatives.\n",
    "The cross validation showed almost no signs of overfitting with this model. \n",
    "Using all of the features resulted in stronger cross validated accuracy and AUC scores.\n",
    "The model that used all of the features is preferable since it minimizes false negatives an has better overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Conclusion\n",
    "\n",
    "The gradient boost model that used all of the features turned out the best performer when it came to detecting credit card fraud. \n",
    "It had high performance, minimized false negatives, and didn't show a tendency to overfit.\n",
    "This result was to be expected since the gradient boost builds on another strong model, the decision tree, to lower potential error.\n",
    "This study gives much more insight into methods and best practices for using supervised learning techniques to detect and, further down the line, combat credit card fraud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
